{"metadata":{"title":"Video mixing","modules":[{"name":"HaishinKit"}],"roleHeading":"Article","role":"article"},"identifier":{"interfaceLanguage":"swift","url":"doc:\/\/HaishinKit\/documentation\/HaishinKit\/videomixing"},"hierarchy":{"paths":[["doc:\/\/HaishinKit\/documentation\/HaishinKit"]]},"abstract":[{"type":"text","text":"HaishinKit provides APIs for overlaying still images on camera footage and for embedding text. These features are collectively referred to as "},{"isActive":true,"type":"reference","identifier":"https:\/\/docs.haishinkit.com\/swift\/latest\/documentation\/haishinkit\/screenobject"},{"type":"text","text":"."},{"type":"text","text":" "},{"type":"text","text":"Filtering with CIFilter is also supported, and for use cases such as applying a mosaic effect to camera footage, the use of CIFilter is recommended."}],"sections":[],"kind":"article","primaryContentSections":[{"content":[{"type":"heading","level":2,"text":"Usage","anchor":"Usage"},{"type":"paragraph","inlineContent":[{"type":"text","text":"Here is an overview of how to use the typical ScreenObject objects."}]},{"type":"heading","level":3,"text":"ImageScreenObject","anchor":"ImageScreenObject"},{"type":"paragraph","inlineContent":[{"text":"An example of compositing images.","type":"text"}]},{"type":"codeListing","syntax":"swift","code":["let imageScreenObject = ImageScreenObject()","let imageURL = URL(fileURLWithPath: Bundle.main.path(forResource: \"game_jikkyou\", ofType: \"png\") ?? \"\")","if let provider = CGDataProvider(url: imageURL as CFURL) {","  imageScreenObject.verticalAlignment = .bottom","  imageScreenObject.layoutMargin = .init(top: 0, left: 0, bottom: 16, right: 0)","  imageScreenObject.cgImage = CGImage(","    pngDataProviderSource: provider,","    decode: nil,","    shouldInterpolate: false,","    intent: .defaultIntent","  )","} else {","  print(\"no image\")","}","","try? await mixer.screen.addChild(imageScreenObject)"]},{"type":"heading","level":3,"text":"VideoTrackScreenObject","anchor":"VideoTrackScreenObject"},{"type":"paragraph","inlineContent":[{"type":"text","text":"There may be situations where you want to capture the scenery with the rear camera while showing your facial expression with the front camera."}]},{"type":"paragraph","inlineContent":[{"type":"text","text":"First, set up the cameras as follows. Make sure to remember the track numbers, as they will be used later."}]},{"type":"codeListing","syntax":"swift","code":["Task {","  let back = AVCaptureDevice.default(.builtInWideAngleCamera, for: .video, position: .back)","  try? await mixer.attachVideo(back, track: 0)","  let front = AVCaptureDevice.default(.builtInWideAngleCamera, for: .video, position: .front)","  try? await mixer.attachVideo(front, track: 1)","}"]},{"type":"paragraph","inlineContent":[{"type":"text","text":"Track number 0 is designed to be rendered across the entire screen. In this case, we are specifying where to render track number 1."}]},{"type":"codeListing","syntax":"swift","code":["Task { @ScreenActor in","  let videoScreenObject = VideoTrackScreenObject()","  videoScreenObject.cornerRadius = 32.0","  videoScreenObject.track = 1","  videoScreenObject.horizontalAlignment = .right","  videoScreenObject.layoutMargin = .init(top: 16, left: 0, bottom: 0, right: 16)","  videoScreenObject.size = .init(width: 160 * 2, height: 90 * 2)","  \/\/ You can add a CIFilter-based filter using the registerVideoEffect API.","  _ = videoScreenObject.registerVideoEffect(MonochromeEffect())","","  try? await mixer.screen.addChild(videoScreenObject)","}"]}],"kind":"content"}],"variants":[{"traits":[{"interfaceLanguage":"swift"}],"paths":["\/documentation\/haishinkit\/videomixing"]}],"schemaVersion":{"minor":3,"major":0,"patch":0},"references":{"doc://HaishinKit/documentation/HaishinKit":{"role":"collection","url":"\/documentation\/haishinkit","abstract":[{"text":"メインモジュールです。","type":"text"}],"type":"topic","title":"HaishinKit","identifier":"doc:\/\/HaishinKit\/documentation\/HaishinKit","kind":"symbol"}}}