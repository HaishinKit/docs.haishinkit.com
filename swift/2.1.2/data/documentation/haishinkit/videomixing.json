{"hierarchy":{"paths":[["doc:\/\/HaishinKit\/documentation\/HaishinKit"]]},"schemaVersion":{"major":0,"minor":3,"patch":0},"metadata":{"title":"Video mixing","role":"article","roleHeading":"Article","modules":[{"name":"HaishinKit"}]},"sections":[],"kind":"article","abstract":[{"text":"HaishinKit provides APIs for overlaying still images on camera footage and for embedding text. These features are collectively referred to as ","type":"text"},{"type":"reference","identifier":"https:\/\/docs.haishinkit.com\/swift\/latest\/documentation\/haishinkit\/screenobject","isActive":true},{"text":".","type":"text"},{"text":" ","type":"text"},{"text":"Filtering with CIFilter is also supported, and for use cases such as applying a mosaic effect to camera footage, the use of CIFilter is recommended.","type":"text"}],"primaryContentSections":[{"content":[{"text":"Usage","type":"heading","anchor":"Usage","level":2},{"type":"paragraph","inlineContent":[{"type":"text","text":"Here is an overview of how to use the typical ScreenObject objects."}]},{"text":"ImageScreenObject","type":"heading","anchor":"ImageScreenObject","level":3},{"type":"paragraph","inlineContent":[{"text":"An example of compositing images.","type":"text"}]},{"syntax":"swift","type":"codeListing","code":["let imageScreenObject = ImageScreenObject()","let imageURL = URL(fileURLWithPath: Bundle.main.path(forResource: \"game_jikkyou\", ofType: \"png\") ?? \"\")","if let provider = CGDataProvider(url: imageURL as CFURL) {","  imageScreenObject.verticalAlignment = .bottom","  imageScreenObject.layoutMargin = .init(top: 0, left: 0, bottom: 16, right: 0)","  imageScreenObject.cgImage = CGImage(","    pngDataProviderSource: provider,","    decode: nil,","    shouldInterpolate: false,","    intent: .defaultIntent","  )","} else {","  print(\"no image\")","}","","try? await mixer.screen.addChild(imageScreenObject)"]},{"text":"VideoTrackScreenObject","type":"heading","anchor":"VideoTrackScreenObject","level":3},{"type":"paragraph","inlineContent":[{"type":"text","text":"There may be situations where you want to capture the scenery with the rear camera while showing your facial expression with the front camera."}]},{"type":"paragraph","inlineContent":[{"type":"text","text":"First, set up the cameras as follows. Make sure to remember the track numbers, as they will be used later."}]},{"syntax":"swift","type":"codeListing","code":["Task {","  let back = AVCaptureDevice.default(.builtInWideAngleCamera, for: .video, position: .back)","  try? await mixer.attachVideo(back, track: 0)","  let front = AVCaptureDevice.default(.builtInWideAngleCamera, for: .video, position: .front)","  try? await mixer.attachVideo(front, track: 1)","}"]},{"type":"paragraph","inlineContent":[{"type":"text","text":"Track number 0 is designed to be rendered across the entire screen. In this case, we are specifying where to render track number 1."}]},{"syntax":"swift","type":"codeListing","code":["Task { @ScreenActor in","  let videoScreenObject = VideoTrackScreenObject()","  videoScreenObject.cornerRadius = 32.0","  videoScreenObject.track = 1","  videoScreenObject.horizontalAlignment = .right","  videoScreenObject.layoutMargin = .init(top: 16, left: 0, bottom: 0, right: 16)","  videoScreenObject.size = .init(width: 160 * 2, height: 90 * 2)","  \/\/ You can add a CIFilter-based filter using the registerVideoEffect API.","  _ = videoScreenObject.registerVideoEffect(MonochromeEffect())","","  try? await mixer.screen.addChild(videoScreenObject)","}"]}],"kind":"content"}],"variants":[{"traits":[{"interfaceLanguage":"swift"}],"paths":["\/documentation\/haishinkit\/videomixing"]}],"identifier":{"url":"doc:\/\/HaishinKit\/documentation\/HaishinKit\/videomixing","interfaceLanguage":"swift"},"references":{"doc://HaishinKit/documentation/HaishinKit":{"role":"collection","title":"HaishinKit","url":"\/documentation\/haishinkit","abstract":[{"text":"メインモジュールです。","type":"text"}],"kind":"symbol","identifier":"doc:\/\/HaishinKit\/documentation\/HaishinKit","type":"topic"}}}